{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 불러오기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 기본"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install numpy \n",
    "# !conda install pandas\n",
    "# !conda install scikit-learn\n",
    "# !conda install scipy\n",
    "# !conda install tensorflow\n",
    "# !conda install matplotlib\n",
    "# !conda install seaborn\n",
    "# !pip install ydata-profiling\n",
    "\n",
    "# !pip install xgboost\n",
    "# !pip install lightgbm\n",
    "# !pip install catboost\n",
    "# !pip install ipywidgets\n",
    "# !jupyter nbextension enable --py widgetsnbextension\n",
    "# !pip install hyperopt\n",
    "# !pip install -U imbalanced-learn\n",
    "# !pip install missingno\n",
    "# !pip install shap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn import impute\n",
    "from sklearn.impute import KNNImputer\n",
    "from sklearn.experimental import enable_iterative_imputer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 리샘플링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler, \n",
    "    ADASYN, \n",
    "    SMOTE\n",
    ")\n",
    "from imblearn.under_sampling import (\n",
    "    RandomUnderSampler, \n",
    "    TomekLinks, \n",
    "    CondensedNearestNeighbour, \n",
    "    OneSidedSelection, \n",
    "    EditedNearestNeighbours, \n",
    "    NeighbourhoodCleaningRule\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import skew, kurtosis\n",
    "from scipy.stats import ttest_ind, f_oneway, pearsonr, chi2_contingency\n",
    "from ydata_profiling import ProfileReport"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 회귀"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression as RL\n",
    "from sklearn.neighbors import KNeighborsRegressor as KNNR\n",
    "from sklearn.tree import DecisionTreeRegressor as DTR\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor as RFR\n",
    "from xgboost import XGBRegressor as XGBR\n",
    "from lightgbm import LGBMRegressor as LGBMR\n",
    "from catboost import CatBoostRegressor as CBR\n",
    "\n",
    "from lightgbm import plot_importance as lgbm_plot_importance\n",
    "from xgboost import plot_importance as xgb_plot_importance\n",
    "from catboost import Pool\n",
    "\n",
    "from sklearn.metrics import mean_squared_error as mse\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression as LR\n",
    "from sklearn.neighbors import KNeighborsClassifier as KNNC\n",
    "from sklearn.tree import DecisionTreeClassifier as DTC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier as RFC\n",
    "from xgboost import XGBClassifier as XGBC\n",
    "from lightgbm import LGBMClassifier as LGBMC\n",
    "from catboost import CatBoostClassifier as CBC\n",
    "\n",
    "from sklearn.metrics import confusion_matrix as cmatrix\n",
    "from sklearn.metrics import classification_report as creport\n",
    "from sklearn.metrics import recall_score as recall\n",
    "from sklearn.metrics import accuracy_score as accuracy\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import make_scorer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 교차검증"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "\n",
    "from catboost import cv\n",
    "\n",
    "from hyperopt import hp\n",
    "from hyperopt import STATUS_OK\n",
    "from hyperopt import fmin, tpe, Trials\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    StratifiedKFold, # 분류\n",
    "    KFold, # 회귀\n",
    "    # GroupKFold, \n",
    "    # RepeatedKFold, \n",
    "    # StratifiedGroupKFold, \n",
    "    # RepeatedStratifiedKFold\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 비즈니스 이해"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.inspection import permutation_importance\n",
    "from sklearn.inspection import PartialDependenceDisplay, partial_dependence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rc('font', family='Malgun Gothic')\n",
    "sns.set(font=\"Malgun Gothic\",\n",
    "        rc={\"axes.unicode_minus\":False}, # 마이너스 부호 깨짐 현상 해결\n",
    "        style='darkgrid')  \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import shap\n",
    "tf.compat.v1.disable_v2_behavior() # shap 그래프 tf1 버전 지원 tf2 비활성화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터 로드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '../분류데이터'\n",
    "\n",
    "x_train = pd.read_csv(f'{folder_path}/x_train.csv', sep=',', encoding='utf-8')\n",
    "y_train = pd.read_csv(f'{folder_path}/y_train.csv', sep=',', encoding='utf-8')\n",
    "x_val = pd.read_csv(f'{folder_path}/x_test.csv', sep=',', encoding='utf-8')\n",
    "y_val = pd.read_csv(f'{folder_path}/y_test.csv', sep=',', encoding='utf-8')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HyperOpt CV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- search space\n",
    "- 목적 함수\n",
    "- 목적 함수의 최솟값을 찾는 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 검색공간\n",
    "xgbc_search_space = {'max_depth': hp.quniform('max_depth', 5, 20, 1), \n",
    "                'min_child_weight': hp.quniform('min_child_weight', 1, 2, 1),\n",
    "                'colsample_bytree': hp.uniform('colsample_bytree', 0.5, 1),\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 목적함수\n",
    "def objective_func(xgbc_search_space):\n",
    "    # fmin은 실수값을 반환해서 정수형 변환\n",
    "    xgb_clf = XGBC(n_estimators = 100, \n",
    "                   max_depth = int(xgbc_search_space['max_depth']),\n",
    "                   min_child_weight = int(xgbc_search_space['min_child_weight']),\n",
    "                   learning_rate = xgbc_search_space['learning_rate'],\n",
    "                   colsample_bytree = xgbc_search_space['colsample_bytree'],\n",
    "                   eval_metric = 'logloss'\n",
    "                   )\n",
    "    cv_score = cross_val_score(xgb_clf, x_train, y_train, scoring=make_scorer(accuracy, greater_is_better=True), cv=3)\n",
    "    \n",
    "    # fmin은 최소를 찾는 함수이고, accuracy는 높을수록 좋은 점수라서 -1 곱하기\n",
    "    return {'loss':-1 * np.mean(cv_score), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = Trials()\n",
    "xgbc_best_score = fmin(fn=objective_func,        # 목적함수\n",
    "                  space=xgbc_search_space,  # 검색공간\n",
    "                  algo=tpe.suggest,         # Tree structured parsen estimator (항상 넣을 것)\n",
    "                  max_evals=5,              # 최대 수행횟수\n",
    "                  trials=trial,             # 입력한 결과값 저장할 trials 객체 (문서 리스트들)\n",
    "                  rstate=np.random.default_rng(seed=0) # 랜덤시드값 안주는 것이 좋은 성능으로 나옴\n",
    "                  )\n",
    "\n",
    "print('best:', xgbc_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial.results, trial.vals, trial.best_trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'colsample_bytree : {round(xgbc_best_score[\"colsample_bytree\"], 5)}')\n",
    "print(f'max_depth : {int(xgbc_best_score[\"max_depth\"])}')\n",
    "print(f'min_child_weight : {int(xgbc_best_score[\"min_child_weight\"])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fmin으로 도출한 파라미터를 그대로 다시 학습\n",
    "model = XGBC(\n",
    "               n_estimators=200, \n",
    "               max_depth=int(xgbc_best_score['max_depth']), \n",
    "               min_child_weight=int(xgbc_best_score['min_child_weight']), \n",
    "               colsample_bytree=round(xgbc_best_score['colsample_bytree'], 5)   \n",
    "              )\n",
    "\n",
    "model.fit(x_train, y_train, early_stopping_rounds=100, \n",
    "            eval_metric=\"auc\", eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = model.predict_proba(x_test)[:,1]\n",
    "\n",
    "xgb_roc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(f'ROC AUC: {xgb_roc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(search_space):\n",
    "    model =  LGBMC(\n",
    "                      n_estimators=100, \n",
    "                      num_leaves=int(search_space['num_leaves']),\n",
    "                      max_depth=int(search_space['max_depth']),\n",
    "                      min_child_samples=int(search_space['min_child_samples']), \n",
    "                      subsample=search_space['subsample'],\n",
    "                      learning_rate=search_space['learning_rate']\n",
    "                     )\n",
    "\n",
    "    roc_auc_list = []\n",
    "    \n",
    "    kf = StratifiedKFold(n_splits=3)\n",
    "    for train_index, val_index in kf.split(x_train):\n",
    "        # KFold로 데이터 분리\n",
    "        x_train_kf, y_train_kf = x_train.iloc[train_index], y_train.iloc[train_index]\n",
    "        x_val, y_val = x_train.iloc[val_index], y_train.iloc[val_index]\n",
    "\n",
    "        model.fit(\n",
    "                    x_train_kf, y_train_kf, \n",
    "                    early_stopping_rounds=30, \n",
    "                    eval_metric=\"auc\",\n",
    "                    eval_set=[(x_train_kf, y_train_kf), (x_val, y_val)]\n",
    "                    )\n",
    "\n",
    "        # 1로 예측한 확률값 추출후 roc auc 계산\n",
    "        score = roc_auc_score(y_val, model.predict_proba(x_val)[:, 1]) \n",
    "        roc_auc_list.append(score)\n",
    "    \n",
    "    return -1 * np.mean(roc_auc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials = Trials()\n",
    "\n",
    "# fmin()함수를 호출. max_evals지정된 횟수만큼 반복 후 목적함수의 최소값을 가지는 최적 입력값 추출. \n",
    "lgbmc_best_score = fmin(fn=objective_func, space=lgbmc_search_space, algo=tpe.suggest,\n",
    "            max_evals=50, # 최대 반복 횟수를 지정합니다.\n",
    "            trials=trials, rstate=np.random.default_rng(seed=30))\n",
    "\n",
    "print('best:', lgbmc_best_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lgbm_clf =  LGBMC(\n",
    "                  n_estimators=500, \n",
    "                  num_leaves=int(lgbmc_best_score['num_leaves']),\n",
    "                  max_depth=int(lgbmc_best_score['max_depth']),\n",
    "                  min_child_samples=int(lgbmc_best_score['min_child_samples']), \n",
    "                  subsample=round(lgbmc_best_score['subsample'], 5),\n",
    "                  learning_rate=round(lgbmc_best_score['learning_rate'], 5)\n",
    "                 )\n",
    "\n",
    "lgbm_clf.fit(x_train, y_train, early_stopping_rounds=100, \n",
    "            eval_metric=\"auc\",eval_set=[(x_train, y_train), (x_val, y_val)])\n",
    "\n",
    "y_pred = lgbm_clf.predict_proba(x_test)[:,1]\n",
    "\n",
    "lgbm_roc_score = roc_auc_score(y_test, y_pred)\n",
    "print(f'ROC AUC: {lgbm_roc_score:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trials에 담긴 각 시도의 x, y, loss를 데이터프레임으로 확인\n",
    "losses = [loss_dict['loss'] for loss_dict in trial.results]\n",
    "\n",
    "result_df = pd.DataFrame({'x': trial.vals['x'],\n",
    "                          'y': trial.vals['y'],\n",
    "                          'losses': losses})\n",
    "result_df"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
